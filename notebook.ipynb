{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "### TODO\n",
    "#### We are using a CNN, max pooling, and n-grams (a sequence of n words in a sentence) to construct this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imporant Documentation\n",
    "\n",
    "### PyTorch Resources:\n",
    "#####    - https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "#####    - https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "#####    - https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "#####    - https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html\n",
    "#####    - https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "#####    - https://towardsdatascience.com/understanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058#:~:text=An%20N%2Dgram%20means%20a,3%2Dgram%20(trigram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "TRAINING_MODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenize data and build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, vocab_size, seq_len):\n",
    "        self.file_name = 'clickbait_data.csv'\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab = None\n",
    "        self.x_tokenized = None\n",
    "        self.x_padded = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def load_dataset(self):\n",
    "        # Load dataset from local directory \n",
    "        df = pd.read_csv(self.file_name)\n",
    "        df = shuffle(df)\n",
    "        self.x = df['headline'].to_numpy()\n",
    "        self.y = df['clickbait'].to_numpy()\n",
    "\n",
    "    def clean_data(self):\n",
    "        # Clean data by removing all special characters. Convert words to lowercase\n",
    "        self.x = [re.sub(r'\\'','', headline).lower() for headline in self.x]\n",
    "        self.x = [re.sub(r'[^A-Za-z0-9]+',' ', headline).lower() for headline in self.x]\n",
    "\n",
    "    def tokenization(self):\n",
    "        # Tokenize all headlines\n",
    "        self.x = [nltk.tokenize.wordpunct_tokenize(headline) for headline in self.x]\n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Build vocab and return 'vocab_size' most common words\n",
    "        self.vocab = dict()\n",
    "\n",
    "        fdist = nltk.FreqDist()\n",
    "        for headline in self.x:\n",
    "            for word in headline:\n",
    "                fdist[word] += 1\n",
    "        \n",
    "        common_words = fdist.most_common(self.vocab_size)\n",
    "\n",
    "        for count, word in enumerate(common_words):\n",
    "            self.vocab[word[0]] = count+1\n",
    "    \n",
    "    def word_to_idx(self):\t\n",
    "        # Convert each token into index based representation \n",
    "        self.x_tokenized = list()\n",
    "        \n",
    "        for sentence in self.x:\n",
    "            temp = list()\n",
    "            for word in sentence:\n",
    "                if word in self.vocab.keys():\n",
    "                    temp.append(self.vocab[word])\n",
    "            self.x_tokenized.append(temp)\n",
    "    \n",
    "    def padding_sentences(self):\n",
    "        # Make all sentences equal length. \n",
    "        # If sentence is smaller than minimum length, pad it \n",
    "        idx = 0\n",
    "        self.x_padded = list()\n",
    "\n",
    "        for sentence in self.x_tokenized:\n",
    "            while len(sentence) < self.seq_len:\n",
    "                sentence.insert(len(sentence), idx)\n",
    "            while len(sentence) > self.seq_len:\n",
    "                print(\"Sentence is long, consider increasing the sequence length to prevent vocab dropping.\")\n",
    "                sentence.pop()\n",
    "            self.x_padded.append(sentence)\n",
    "            \n",
    "        self.x_padded = np.array(self.x_padded)\n",
    "\n",
    "    def split_data(self):\n",
    "        # Split data into training and testing sets\n",
    "        trnSize = int(len(self.x_padded) * .8)\n",
    "        tstSize = int(len(self.x_padded) * .2)\n",
    "        self.x_train = self.x_padded[:trnSize]\n",
    "        self.y_train = self.y[:trnSize]\n",
    "        self.x_test = self.x_padded[trnSize:]\n",
    "        self.y_test = self.y[trnSize:]\n",
    "    \n",
    "    def get_tokenized_string(self, sentence) -> list:\n",
    "        # Load dataset from local directory \n",
    "        string = sentence\n",
    "        string = re.sub(r'\\'','', string).lower()\n",
    "        string = re.sub(r'[^A-Za-z0-9]+',' ', string).lower()\n",
    "        string = nltk.tokenize.wordpunct_tokenize(string)\n",
    "        x_tokenized = list()\n",
    "        idx = 0\n",
    "        for word in string:\n",
    "            if word in self.vocab.keys():\n",
    "                x_tokenized.append(self.vocab[word])\n",
    "        while len(x_tokenized) < self.seq_len:\n",
    "            x_tokenized.insert(len(string), idx)\n",
    "        while len(x_tokenized) > self.seq_len:\n",
    "            print(\"Sentence is long, consider increasing the sequence length to prevent vocab dropping.\")\n",
    "            x_tokenized.pop()\n",
    "        x_padded = x_tokenized\n",
    "        return np.array([x_padded])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineClassifier(torch.nn.ModuleList):\n",
    "    def __init__(self, seq_len, num_words, embedding_size, dropout, out_size, stride, filters):\n",
    "        super(HeadlineClassifier, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.num_words = num_words\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Dropout (used to reduce chance of overfitting by \"dropping\" units in neural net). Probability (p) set to 0.25\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # Kernel sizes for CNN\n",
    "        #pass it as params when we change the implmentation. Can keep it like this for now\n",
    "        self.filters = filters\n",
    "\n",
    "        # Output size for convolutions\n",
    "        self.out_size = out_size\n",
    "        # Number of strides for convolutions\n",
    "        self.stride = stride\n",
    "\n",
    "        # Embedding layer (lookup table that stores embeddings of a fixed dictionary and size)\n",
    "        self.embedding = torch.nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0).cuda()\n",
    "\n",
    "        # Convolution layers (each is a 1D convolution over an input)\n",
    "        self.clayers = [torch.nn.Conv1d(self.seq_len, self.out_size, fltr, self.stride) for fltr in self.filters]\n",
    "        for layer in self.clayers:\n",
    "            layer = layer.cuda()\n",
    "        \n",
    "            \n",
    "        # Max pooling layers (each applies 1D max pooling to input) \n",
    "        self.poollayers = [torch.nn.MaxPool1d(fltr, self.stride) for fltr in self.filters]\n",
    "        for layer in self.poollayers:\n",
    "            layer = layer.cuda()\n",
    "\n",
    "        # Fully connected layer (applies linear transformation to data)\n",
    "        self.fc = torch.nn.Linear(self.size_of_input(), 1)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        self.train_eval_info = {\n",
    "            \"accuracy\": 0,\n",
    "            \"precision\": 0,\n",
    "            \"recall\": 0,\n",
    "            \"tpr\": 0,\n",
    "            \"fpr\": 0,\n",
    "            \"tp\": 0,\n",
    "            \"fp\": 0,\n",
    "            \"tn\": 0,\n",
    "            \"fn\": 0\n",
    "        }\n",
    "\n",
    "        self.test_eval_info = {\n",
    "            \"accuracy\": 0,\n",
    "            \"precision\": 0,\n",
    "            \"recall\": 0,\n",
    "            \"tpr\": 0,\n",
    "            \"fpr\": 0,\n",
    "            \"tp\": 0,\n",
    "            \"fp\": 0,\n",
    "            \"tn\": 0,\n",
    "            \"fn\": 0\n",
    "        }\n",
    "\n",
    "    \n",
    "    def size_of_input(self):\n",
    "        # Calculate input size for linear layer \n",
    "        pout = 0\n",
    "        for filter in self.filters:\n",
    "            cout = math.floor(((self.embedding_size - (filter - 1) - 1)/self.stride) + 1)\n",
    "            pout += math.floor(((cout - (filter - 1) - 1) / self.stride) + 1)\n",
    "        \n",
    "        return pout * self.out_size\n",
    "\n",
    "    '''Create forward pass of neural network. Consists of mainly ordering the different types of layers\n",
    "        Steps:\n",
    "            1. Pass tokenized words through embedding layer\n",
    "            2. Pass each embedded sentence through each convolution and max pooling layer\n",
    "            3. Reduce vector to linear layer\n",
    "    '''\n",
    "    def forward(self, input_X):\n",
    "        x = self.embedding(input_X)\n",
    "\n",
    "        layerPasses = list()\n",
    "        for i in range(len(self.filters)):\n",
    "            temp = self.clayers[i](x)\n",
    "            #TODO: Why not sigmoid (there are a few common functions we can try)? Maybe this can be a question we answer\n",
    "            temp = torch.relu(temp).cuda()\n",
    "            temp = self.poollayers[i](temp)\n",
    "            layerPasses.append(temp)\n",
    "\n",
    "        unn = torch.cat(layerPasses, 2)\n",
    "        unn = unn.reshape(unn.size(0), -1)\n",
    "\n",
    "        output = torch.sigmoid(self.dropout(self.fc(unn))).squeeze()\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Returns: Training Loss, Testing Loss, Training Accuracy, Testing Accuracy, Evaluated Training List, Evaluated Testing List\n",
    "def train(model, dataset, learning_rate, batch_size, train_data, test_data, numOfIter):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size)\n",
    "    # for x, y in train_loader:\n",
    "    #         x = x.to('cuda')\n",
    "    #         y = y.type(torch.FloatTensor)\n",
    "    #         y = y.to('cuda')\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size)\n",
    "    # for x, y in test_loader:\n",
    "    #         x = x.to('cuda')\n",
    "    #         y = y.to('cuda')\n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    trainLoss, testLoss, trainAccuracy, testAccuracy = [], [], [], []\n",
    "    for iter in range(numOfIter):\n",
    "        model.train()\n",
    "        train_predictions = []\n",
    "\n",
    "        for x,y in train_loader:\n",
    "            y = y.type(torch.cuda.FloatTensor)\n",
    "            pred = model.forward(x) # Forward pass on input data\n",
    "            loss = torch.nn.functional.binary_cross_entropy(pred, y) # Measure the Binary Cross Entropy between the target and input probabilities\n",
    "\n",
    "            opt.zero_grad() # Set gradients to zero \n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            train_predictions += list(pred.cpu().detach().numpy()) # Append training predictions \n",
    "\n",
    "        # Evaluate model\n",
    "        model.eval() # Put model in evaluation mode\n",
    "        test_predictions = []\n",
    "        with torch.no_grad(): # Disable gradient calculation \n",
    "            for x, y in test_loader:\n",
    "                pred = model.forward(x)\n",
    "                test_predictions += list(pred.cpu().detach().numpy()) # Append test predictions\n",
    "\n",
    "        # Get model accuracy \n",
    "        # train_eval = [accuracy, precision, recall, true-positive-rate, false-positive-rate, true_pos, false_pos, true_neg, false_neg]\n",
    "        train_eval = evaluate(dataset.y_train, train_predictions)\n",
    "        test_eval = evaluate(dataset.y_test, test_predictions)\n",
    "        train_loss = loss.item()\n",
    "        test_loss = loss.item()\n",
    "        \n",
    "        # Gather training and testing loss & accuracy\n",
    "        trainLoss.append(train_loss)\n",
    "        testLoss.append(test_loss)\n",
    "        trainAccuracy.append(train_eval[0])\n",
    "        testAccuracy.append(test_eval[0])\n",
    "        \n",
    "        # Print training and testing accuracy for each iteration\n",
    "        print(\"Training -- Iteration: %d, Loss: %.5f, Accuracy: %.5f, Precision: %.5f, Recall: %.5f, TPR: %.5f, FPR: %.5f\" % (iter+1, train_loss, train_eval[0], train_eval[1], train_eval[2], train_eval[3], train_eval[4]))\n",
    "        print(\"Testing -- Iteration: %d, Loss: %.5f, Accuracy: %.5f, Precision: %.5f, Recall: %.5f, TPR: %.5f, FPR: %.5f\" % (iter+1, test_loss, test_eval[0], test_eval[1], test_eval[2], test_eval[3], test_eval[4]))\n",
    "\n",
    "    # Update model's evaluation metrics\n",
    "    model.train_eval_info['trn_accuracy'] = trainAccuracy\n",
    "    model.train_eval_info['precision'] = train_eval[1]\n",
    "    model.train_eval_info['recall'] = train_eval[2]\n",
    "    model.train_eval_info['tpr'] = train_eval[3]\n",
    "    model.train_eval_info['fpr'] = train_eval[4]\n",
    "    model.train_eval_info['tp'] = train_eval[5]\n",
    "    model.train_eval_info['fp'] = train_eval[6]\n",
    "    model.train_eval_info['tn'] = train_eval[7]\n",
    "    model.train_eval_info['fn'] = train_eval[8]\n",
    "\n",
    "    model.test_eval_info['trn_accuracy'] = trainAccuracy\n",
    "    model.test_eval_info['precision'] = train_eval[1]\n",
    "    model.test_eval_info['recall'] = train_eval[2]\n",
    "    model.test_eval_info['tpr'] = train_eval[3]\n",
    "    model.test_eval_info['fpr'] = train_eval[4]\n",
    "    model.test_eval_info['tp'] = train_eval[5]\n",
    "    model.test_eval_info['fp'] = train_eval[6]\n",
    "    model.test_eval_info['tn'] = train_eval[7]\n",
    "    model.test_eval_info['fn'] = train_eval[8]\n",
    "\n",
    "    return (trainLoss, testLoss)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Supporting Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass(torch.utils.data.TensorDataset):\n",
    "   def __init__(self, x, y):\n",
    "      self.x = x\n",
    "      self.y = y\n",
    "      \n",
    "   def __len__(self):\n",
    "      return len(self.x)\n",
    "      \n",
    "   def __getitem__(self, idx):\n",
    "      return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of model \n",
    "# Returns Accuracy, Precision, Recall, True-Positive-Rate, False-Positive-Rate\n",
    "def evaluate(actual, predictions):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    for true, pred in zip(actual, predictions):\n",
    "        if (pred >= .5) and (true == 1): # True positive (prediction is 'clickbait' and actual is 'clickbait')\n",
    "            true_pos += 1\n",
    "        elif (pred >= .5) and (true == 0): # False positive (prediction is 'clickbait' and actual is 'not clickbait')\n",
    "            false_pos += 1\n",
    "        elif (pred < .5) and (true == 0): # True negative (prediction is 'not clickbait' and actual is 'not clickbait')\n",
    "            true_neg += 1\n",
    "        elif (pred < .5) and (true == 1): # False negative (prediction is 'not clickbait' and actual is 'clickbait')\n",
    "            false_neg += 1\n",
    "\n",
    "    # Return accuracy of model\n",
    "    accuracy = (true_pos + true_neg) / len(actual)\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    true_pos_rate = true_pos / (true_pos + false_neg)\n",
    "    false_pos_rate = false_pos / (false_pos + true_neg)\n",
    "\n",
    "    return [accuracy, precision, recall, true_pos_rate, false_pos_rate, true_pos, false_pos, true_neg, false_neg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(tp, fp, tn, fn):\n",
    "    arr = [[tp, fn],\n",
    "           [fp, tn]]\n",
    "    df_cm = pd.DataFrame(arr, range(6), range(6))\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  32000\n",
      "Dataset training size:  25600\n",
      "Dataset testing size:  6400\n"
     ]
    }
   ],
   "source": [
    "# Initialization variables\n",
    "seq_len = 30\n",
    "\n",
    "# Initialize instance of Preprocessing class\n",
    "dataset = Preprocessing(100_000, seq_len)\n",
    "\n",
    "# Load dataset\n",
    "dataset.load_dataset()\n",
    "\n",
    "# Clean and tokenize dataset\n",
    "dataset.clean_data()\n",
    "dataset.tokenization()\n",
    "\n",
    "# Build vocab \n",
    "dataset.build_vocab()\n",
    "\n",
    "# Index words and pad headline sentences\n",
    "dataset.word_to_idx()\n",
    "dataset.padding_sentences()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "dataset.split_data()\n",
    "\n",
    "# Print data specifics:\n",
    "print(\"Dataset size: \", len(dataset.x))\n",
    "#print(\"Dataset vocab: \", dataset.vocab)\n",
    "print(\"Dataset training size: \", len(dataset.y_train))\n",
    "print(\"Dataset testing size: \", len(dataset.x_test))\n",
    "\n",
    "# Initialize model (TODO: optimize parameters)\n",
    "vocab_size = len(dataset.vocab)\n",
    "embedding_size = 64\n",
    "dropout = 0.25\n",
    "out_size = 40\n",
    "stride = 2\n",
    "filters = [2,3,4,5]\n",
    "model = HeadlineClassifier(seq_len, vocab_size, embedding_size, dropout, out_size, stride, filters)\n",
    "\n",
    "# Model save paths model\n",
    "save_path = Path(\"model-save-data/model.pth\")\n",
    "cpu_flag_path = Path(\"model-save-data/cpu\")\n",
    "gpu_flag_path = Path(\"model-save-data/gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Found CUDA device. Training on GPU.--------------\n",
      "Training -- Iteration: 1, Loss: 0.47143, Accuracy: 0.66086, Precision: 0.62664, Recall: 0.78636, TPR: 0.78636, FPR: 0.46322\n",
      "Testing -- Iteration: 1, Loss: 0.47143, Accuracy: 0.77484, Precision: 0.76683, Recall: 0.80410, TPR: 0.80410, FPR: 0.25575\n",
      "Training -- Iteration: 2, Loss: 0.23860, Accuracy: 0.70859, Precision: 0.66751, Recall: 0.82455, TPR: 0.82455, FPR: 0.40604\n",
      "Testing -- Iteration: 2, Loss: 0.23860, Accuracy: 0.79453, Precision: 0.80819, Recall: 0.78423, TPR: 0.78423, FPR: 0.19469\n",
      "Training -- Iteration: 3, Loss: 0.38451, Accuracy: 0.72070, Precision: 0.67704, Recall: 0.83790, TPR: 0.83790, FPR: 0.39517\n",
      "Testing -- Iteration: 3, Loss: 0.38451, Accuracy: 0.79312, Precision: 0.76700, Recall: 0.85513, TPR: 0.85513, FPR: 0.27174\n",
      "Training -- Iteration: 4, Loss: 0.15226, Accuracy: 0.72840, Precision: 0.68335, Recall: 0.84545, TPR: 0.84545, FPR: 0.38732\n",
      "Testing -- Iteration: 4, Loss: 0.15226, Accuracy: 0.80359, Precision: 0.81086, Recall: 0.80318, TPR: 0.80318, FPR: 0.19597\n",
      "Training -- Iteration: 5, Loss: 0.13841, Accuracy: 0.74004, Precision: 0.69355, Recall: 0.85480, TPR: 0.85480, FPR: 0.37342\n",
      "Testing -- Iteration: 5, Loss: 0.13841, Accuracy: 0.81094, Precision: 0.81356, Recall: 0.81754, TPR: 0.81754, FPR: 0.19597\n",
      "Training -- Iteration: 6, Loss: 0.39113, Accuracy: 0.74566, Precision: 0.69804, Recall: 0.86077, TPR: 0.86077, FPR: 0.36813\n",
      "Testing -- Iteration: 6, Loss: 0.39113, Accuracy: 0.81094, Precision: 0.84436, Recall: 0.77262, TPR: 0.77262, FPR: 0.14898\n",
      "Training -- Iteration: 7, Loss: 0.26368, Accuracy: 0.74543, Precision: 0.69709, Recall: 0.86289, TPR: 0.86289, FPR: 0.37070\n",
      "Testing -- Iteration: 7, Loss: 0.26368, Accuracy: 0.81109, Precision: 0.79977, Recall: 0.84108, TPR: 0.84108, FPR: 0.22027\n",
      "Training -- Iteration: 8, Loss: 0.11795, Accuracy: 0.75133, Precision: 0.70218, Recall: 0.86792, TPR: 0.86792, FPR: 0.36394\n",
      "Testing -- Iteration: 8, Loss: 0.11795, Accuracy: 0.81922, Precision: 0.82893, Recall: 0.81449, TPR: 0.81449, FPR: 0.17583\n",
      "Training -- Iteration: 9, Loss: 0.36713, Accuracy: 0.75441, Precision: 0.70359, Recall: 0.87436, TPR: 0.87436, FPR: 0.36417\n",
      "Testing -- Iteration: 9, Loss: 0.36713, Accuracy: 0.82000, Precision: 0.81417, Recall: 0.83955, TPR: 0.83955, FPR: 0.20045\n",
      "Training -- Iteration: 10, Loss: 0.24197, Accuracy: 0.75816, Precision: 0.70799, Recall: 0.87405, TPR: 0.87405, FPR: 0.35640\n",
      "Testing -- Iteration: 10, Loss: 0.24197, Accuracy: 0.82625, Precision: 0.83129, Recall: 0.82824, TPR: 0.82824, FPR: 0.17583\n",
      "Training -- Iteration: 11, Loss: 0.39604, Accuracy: 0.75926, Precision: 0.70846, Recall: 0.87640, TPR: 0.87640, FPR: 0.35656\n",
      "Testing -- Iteration: 11, Loss: 0.39604, Accuracy: 0.82953, Precision: 0.82995, Recall: 0.83833, TPR: 0.83833, FPR: 0.17967\n",
      "Training -- Iteration: 12, Loss: 0.37852, Accuracy: 0.76594, Precision: 0.71519, Recall: 0.87939, TPR: 0.87939, FPR: 0.34623\n",
      "Testing -- Iteration: 12, Loss: 0.37852, Accuracy: 0.82875, Precision: 0.86218, Recall: 0.79156, TPR: 0.79156, FPR: 0.13235\n",
      "Training -- Iteration: 13, Loss: 0.23662, Accuracy: 0.76723, Precision: 0.71620, Recall: 0.88080, TPR: 0.88080, FPR: 0.34506\n",
      "Testing -- Iteration: 13, Loss: 0.23662, Accuracy: 0.82984, Precision: 0.83126, Recall: 0.83710, TPR: 0.83710, FPR: 0.17775\n",
      "Training -- Iteration: 14, Loss: 0.36926, Accuracy: 0.76949, Precision: 0.71667, Recall: 0.88701, TPR: 0.88701, FPR: 0.34669\n",
      "Testing -- Iteration: 14, Loss: 0.36926, Accuracy: 0.81922, Precision: 0.78744, Recall: 0.88539, TPR: 0.88539, FPR: 0.25000\n",
      "Training -- Iteration: 15, Loss: 0.38810, Accuracy: 0.77160, Precision: 0.71891, Recall: 0.88764, TPR: 0.88764, FPR: 0.34312\n",
      "Testing -- Iteration: 15, Loss: 0.38810, Accuracy: 0.83594, Precision: 0.84122, Recall: 0.83710, TPR: 0.83710, FPR: 0.16528\n",
      "Training -- Iteration: 16, Loss: 0.06854, Accuracy: 0.77332, Precision: 0.71984, Recall: 0.89070, TPR: 0.89070, FPR: 0.34273\n",
      "Testing -- Iteration: 16, Loss: 0.06854, Accuracy: 0.83609, Precision: 0.82759, Recall: 0.85819, TPR: 0.85819, FPR: 0.18702\n",
      "Training -- Iteration: 17, Loss: 0.06526, Accuracy: 0.77508, Precision: 0.72170, Recall: 0.89125, TPR: 0.89125, FPR: 0.33978\n",
      "Testing -- Iteration: 17, Loss: 0.06526, Accuracy: 0.83797, Precision: 0.82994, Recall: 0.85911, TPR: 0.85911, FPR: 0.18414\n",
      "Training -- Iteration: 18, Loss: 0.21665, Accuracy: 0.77625, Precision: 0.72184, Recall: 0.89471, TPR: 0.89471, FPR: 0.34087\n",
      "Testing -- Iteration: 18, Loss: 0.21665, Accuracy: 0.84172, Precision: 0.83191, Recall: 0.86522, TPR: 0.86522, FPR: 0.18286\n",
      "Training -- Iteration: 19, Loss: 0.36156, Accuracy: 0.78066, Precision: 0.72742, Recall: 0.89369, TPR: 0.89369, FPR: 0.33108\n",
      "Testing -- Iteration: 19, Loss: 0.36156, Accuracy: 0.84641, Precision: 0.85979, Recall: 0.83588, TPR: 0.83588, FPR: 0.14258\n",
      "Training -- Iteration: 20, Loss: 0.23156, Accuracy: 0.78164, Precision: 0.72722, Recall: 0.89738, TPR: 0.89738, FPR: 0.33279\n",
      "Testing -- Iteration: 20, Loss: 0.23156, Accuracy: 0.83953, Precision: 0.82470, Recall: 0.87133, TPR: 0.87133, FPR: 0.19373\n",
      "Training -- Iteration: 21, Loss: 0.36826, Accuracy: 0.78238, Precision: 0.72758, Recall: 0.89880, TPR: 0.89880, FPR: 0.33271\n",
      "Testing -- Iteration: 21, Loss: 0.36826, Accuracy: 0.84156, Precision: 0.82973, Recall: 0.86828, TPR: 0.86828, FPR: 0.18638\n",
      "Training -- Iteration: 22, Loss: 0.20611, Accuracy: 0.78496, Precision: 0.72918, Recall: 0.90273, TPR: 0.90273, FPR: 0.33147\n",
      "Testing -- Iteration: 22, Loss: 0.20611, Accuracy: 0.84391, Precision: 0.83221, Recall: 0.87011, TPR: 0.87011, FPR: 0.18350\n",
      "Training -- Iteration: 23, Loss: 0.05372, Accuracy: 0.78473, Precision: 0.72873, Recall: 0.90320, TPR: 0.90320, FPR: 0.33240\n",
      "Testing -- Iteration: 23, Loss: 0.05372, Accuracy: 0.84625, Precision: 0.83568, Recall: 0.87042, TPR: 0.87042, FPR: 0.17903\n",
      "Training -- Iteration: 24, Loss: 0.05053, Accuracy: 0.78387, Precision: 0.72714, Recall: 0.90477, TPR: 0.90477, FPR: 0.33566\n",
      "Testing -- Iteration: 24, Loss: 0.05053, Accuracy: 0.84625, Precision: 0.83121, Recall: 0.87744, TPR: 0.87744, FPR: 0.18638\n",
      "Training -- Iteration: 25, Loss: 0.04444, Accuracy: 0.79027, Precision: 0.73391, Recall: 0.90697, TPR: 0.90697, FPR: 0.32510\n",
      "Testing -- Iteration: 25, Loss: 0.04444, Accuracy: 0.85141, Precision: 0.85500, Recall: 0.85422, TPR: 0.85422, FPR: 0.15153\n",
      "Training -- Iteration: 26, Loss: 0.52044, Accuracy: 0.78984, Precision: 0.73266, Recall: 0.90893, TPR: 0.90893, FPR: 0.32790\n",
      "Testing -- Iteration: 26, Loss: 0.52044, Accuracy: 0.84437, Precision: 0.82348, Recall: 0.88539, TPR: 0.88539, FPR: 0.19853\n",
      "Training -- Iteration: 27, Loss: 0.19848, Accuracy: 0.79324, Precision: 0.73657, Recall: 0.90933, TPR: 0.90933, FPR: 0.32153\n",
      "Testing -- Iteration: 27, Loss: 0.19848, Accuracy: 0.85562, Precision: 0.85749, Recall: 0.86064, TPR: 0.86064, FPR: 0.14962\n",
      "Training -- Iteration: 28, Loss: 0.52927, Accuracy: 0.79254, Precision: 0.73582, Recall: 0.90909, TPR: 0.90909, FPR: 0.32269\n",
      "Testing -- Iteration: 28, Loss: 0.52927, Accuracy: 0.85797, Precision: 0.86818, Recall: 0.85147, TPR: 0.85147, FPR: 0.13523\n",
      "Training -- Iteration: 29, Loss: 0.20175, Accuracy: 0.79371, Precision: 0.73605, Recall: 0.91216, TPR: 0.91216, FPR: 0.32339\n",
      "Testing -- Iteration: 29, Loss: 0.20175, Accuracy: 0.85703, Precision: 0.85043, Recall: 0.87408, TPR: 0.87408, FPR: 0.16081\n",
      "Training -- Iteration: 30, Loss: 0.20750, Accuracy: 0.79438, Precision: 0.73721, Recall: 0.91121, TPR: 0.91121, FPR: 0.32114\n",
      "Testing -- Iteration: 30, Loss: 0.20750, Accuracy: 0.85828, Precision: 0.86329, Recall: 0.85880, TPR: 0.85880, FPR: 0.14226\n",
      "Training -- Iteration: 31, Loss: 0.03468, Accuracy: 0.79777, Precision: 0.74032, Recall: 0.91373, TPR: 0.91373, FPR: 0.31686\n",
      "Testing -- Iteration: 31, Loss: 0.03468, Accuracy: 0.86000, Precision: 0.85633, Recall: 0.87256, TPR: 0.87256, FPR: 0.15313\n",
      "Training -- Iteration: 32, Loss: 0.52027, Accuracy: 0.79809, Precision: 0.73981, Recall: 0.91601, TPR: 0.91601, FPR: 0.31850\n",
      "Testing -- Iteration: 32, Loss: 0.52027, Accuracy: 0.85719, Precision: 0.84494, Recall: 0.88264, TPR: 0.88264, FPR: 0.16944\n",
      "Training -- Iteration: 33, Loss: 0.03685, Accuracy: 0.79816, Precision: 0.73970, Recall: 0.91656, TPR: 0.91656, FPR: 0.31888\n",
      "Testing -- Iteration: 33, Loss: 0.03685, Accuracy: 0.85609, Precision: 0.83925, Recall: 0.88875, TPR: 0.88875, FPR: 0.17807\n",
      "Training -- Iteration: 34, Loss: 0.03391, Accuracy: 0.80043, Precision: 0.74249, Recall: 0.91640, TPR: 0.91640, FPR: 0.31422\n",
      "Testing -- Iteration: 34, Loss: 0.03391, Accuracy: 0.86047, Precision: 0.85037, Recall: 0.88233, TPR: 0.88233, FPR: 0.16240\n",
      "Training -- Iteration: 35, Loss: 0.19344, Accuracy: 0.79840, Precision: 0.73943, Recall: 0.91797, TPR: 0.91797, FPR: 0.31982\n",
      "Testing -- Iteration: 35, Loss: 0.19344, Accuracy: 0.85969, Precision: 0.84769, Recall: 0.88447, TPR: 0.88447, FPR: 0.16624\n",
      "Training -- Iteration: 36, Loss: 0.19591, Accuracy: 0.79770, Precision: 0.73757, Recall: 0.92064, TPR: 0.92064, FPR: 0.32386\n",
      "Testing -- Iteration: 36, Loss: 0.19591, Accuracy: 0.85516, Precision: 0.83529, Recall: 0.89273, TPR: 0.89273, FPR: 0.18414\n",
      "Training -- Iteration: 37, Loss: 0.02853, Accuracy: 0.80453, Precision: 0.74525, Recall: 0.92198, TPR: 0.92198, FPR: 0.31158\n",
      "Testing -- Iteration: 37, Loss: 0.02853, Accuracy: 0.86547, Precision: 0.86475, Recall: 0.87347, TPR: 0.87347, FPR: 0.14290\n",
      "Training -- Iteration: 38, Loss: 0.20350, Accuracy: 0.80129, Precision: 0.74156, Recall: 0.92143, TPR: 0.92143, FPR: 0.31749\n",
      "Testing -- Iteration: 38, Loss: 0.20350, Accuracy: 0.86187, Precision: 0.85035, Recall: 0.88570, TPR: 0.88570, FPR: 0.16304\n",
      "Training -- Iteration: 39, Loss: 0.19126, Accuracy: 0.80574, Precision: 0.74694, Recall: 0.92143, TPR: 0.92143, FPR: 0.30863\n",
      "Testing -- Iteration: 39, Loss: 0.19126, Accuracy: 0.86766, Precision: 0.87388, Recall: 0.86614, TPR: 0.86614, FPR: 0.13075\n",
      "Training -- Iteration: 40, Loss: 0.36140, Accuracy: 0.80723, Precision: 0.74818, Recall: 0.92284, TPR: 0.92284, FPR: 0.30708\n",
      "Testing -- Iteration: 40, Loss: 0.36140, Accuracy: 0.86859, Precision: 0.87784, Recall: 0.86308, TPR: 0.86308, FPR: 0.12564\n",
      "Training -- Iteration: 41, Loss: 0.18938, Accuracy: 0.80828, Precision: 0.74931, Recall: 0.92323, TPR: 0.92323, FPR: 0.30537\n",
      "Testing -- Iteration: 41, Loss: 0.18938, Accuracy: 0.87062, Precision: 0.88622, Recall: 0.85697, TPR: 0.85697, FPR: 0.11509\n",
      "Training -- Iteration: 42, Loss: 0.02395, Accuracy: 0.80430, Precision: 0.74401, Recall: 0.92441, TPR: 0.92441, FPR: 0.31446\n",
      "Testing -- Iteration: 42, Loss: 0.02395, Accuracy: 0.86859, Precision: 0.86822, Recall: 0.87592, TPR: 0.87592, FPR: 0.13907\n",
      "Training -- Iteration: 43, Loss: 0.03141, Accuracy: 0.80375, Precision: 0.74298, Recall: 0.92536, TPR: 0.92536, FPR: 0.31648\n",
      "Testing -- Iteration: 43, Loss: 0.03141, Accuracy: 0.85969, Precision: 0.83779, Recall: 0.89976, TPR: 0.89976, FPR: 0.18223\n",
      "Training -- Iteration: 44, Loss: 0.69315, Accuracy: 0.81074, Precision: 0.74962, Recall: 0.92991, TPR: 0.92991, FPR: 0.30708\n",
      "Testing -- Iteration: 44, Loss: 0.69315, Accuracy: 0.87000, Precision: 0.86725, Recall: 0.88050, TPR: 0.88050, FPR: 0.14098\n",
      "Training -- Iteration: 45, Loss: 0.35554, Accuracy: 0.80613, Precision: 0.74532, Recall: 0.92669, TPR: 0.92669, FPR: 0.31306\n",
      "Testing -- Iteration: 45, Loss: 0.35554, Accuracy: 0.86797, Precision: 0.86041, Recall: 0.88539, TPR: 0.88539, FPR: 0.15026\n",
      "Training -- Iteration: 46, Loss: 0.18875, Accuracy: 0.81066, Precision: 0.75035, Recall: 0.92787, TPR: 0.92787, FPR: 0.30521\n",
      "Testing -- Iteration: 46, Loss: 0.18875, Accuracy: 0.86922, Precision: 0.86224, Recall: 0.88570, TPR: 0.88570, FPR: 0.14802\n",
      "Training -- Iteration: 47, Loss: 0.18911, Accuracy: 0.80863, Precision: 0.74816, Recall: 0.92716, TPR: 0.92716, FPR: 0.30855\n",
      "Testing -- Iteration: 47, Loss: 0.18911, Accuracy: 0.86703, Precision: 0.85261, Recall: 0.89456, TPR: 0.89456, FPR: 0.16176\n",
      "Training -- Iteration: 48, Loss: 0.18487, Accuracy: 0.81477, Precision: 0.75293, Recall: 0.93384, TPR: 0.93384, FPR: 0.30296\n",
      "Testing -- Iteration: 48, Loss: 0.18487, Accuracy: 0.87531, Precision: 0.87945, Recall: 0.87622, TPR: 0.87622, FPR: 0.12564\n",
      "Training -- Iteration: 49, Loss: 0.18555, Accuracy: 0.81426, Precision: 0.75353, Recall: 0.93086, TPR: 0.93086, FPR: 0.30102\n",
      "Testing -- Iteration: 49, Loss: 0.18555, Accuracy: 0.87500, Precision: 0.87523, Recall: 0.88111, TPR: 0.88111, FPR: 0.13139\n",
      "Training -- Iteration: 50, Loss: 0.01973, Accuracy: 0.81277, Precision: 0.75149, Recall: 0.93141, TPR: 0.93141, FPR: 0.30451\n",
      "Testing -- Iteration: 50, Loss: 0.01973, Accuracy: 0.87187, Precision: 0.86641, Recall: 0.88600, TPR: 0.88600, FPR: 0.14290\n",
      "Training -- Iteration: 51, Loss: 0.18421, Accuracy: 0.81359, Precision: 0.75220, Recall: 0.93211, TPR: 0.93211, FPR: 0.30358\n",
      "Testing -- Iteration: 51, Loss: 0.18421, Accuracy: 0.87000, Precision: 0.85946, Recall: 0.89150, TPR: 0.89150, FPR: 0.15249\n",
      "Training -- Iteration: 52, Loss: 0.01868, Accuracy: 0.81441, Precision: 0.75250, Recall: 0.93384, TPR: 0.93384, FPR: 0.30366\n",
      "Testing -- Iteration: 52, Loss: 0.01868, Accuracy: 0.87328, Precision: 0.86808, Recall: 0.88692, TPR: 0.88692, FPR: 0.14098\n",
      "Training -- Iteration: 53, Loss: 0.35791, Accuracy: 0.81211, Precision: 0.75008, Recall: 0.93290, TPR: 0.93290, FPR: 0.30731\n",
      "Testing -- Iteration: 53, Loss: 0.35791, Accuracy: 0.87891, Precision: 0.88333, Recall: 0.87928, TPR: 0.87928, FPR: 0.12148\n",
      "Training -- Iteration: 54, Loss: 0.18288, Accuracy: 0.81535, Precision: 0.75361, Recall: 0.93392, TPR: 0.93392, FPR: 0.30187\n",
      "Testing -- Iteration: 54, Loss: 0.18288, Accuracy: 0.87938, Precision: 0.88556, Recall: 0.87744, TPR: 0.87744, FPR: 0.11861\n",
      "Training -- Iteration: 55, Loss: 0.18790, Accuracy: 0.81285, Precision: 0.75041, Recall: 0.93431, TPR: 0.93431, FPR: 0.30723\n",
      "Testing -- Iteration: 55, Loss: 0.18790, Accuracy: 0.87594, Precision: 0.87096, Recall: 0.88906, TPR: 0.88906, FPR: 0.13779\n",
      "Training -- Iteration: 56, Loss: 0.01976, Accuracy: 0.81641, Precision: 0.75500, Recall: 0.93368, TPR: 0.93368, FPR: 0.29954\n",
      "Testing -- Iteration: 56, Loss: 0.01976, Accuracy: 0.87234, Precision: 0.85798, Recall: 0.89914, TPR: 0.89914, FPR: 0.15569\n",
      "Training -- Iteration: 57, Loss: 0.01745, Accuracy: 0.81758, Precision: 0.75544, Recall: 0.93612, TPR: 0.93612, FPR: 0.29962\n",
      "Testing -- Iteration: 57, Loss: 0.01745, Accuracy: 0.87797, Precision: 0.87869, Recall: 0.88325, TPR: 0.88325, FPR: 0.12756\n",
      "Training -- Iteration: 58, Loss: 0.01717, Accuracy: 0.82016, Precision: 0.75835, Recall: 0.93675, TPR: 0.93675, FPR: 0.29511\n",
      "Testing -- Iteration: 58, Loss: 0.01717, Accuracy: 0.87687, Precision: 0.87119, Recall: 0.89089, TPR: 0.89089, FPR: 0.13779\n",
      "Training -- Iteration: 59, Loss: 0.01411, Accuracy: 0.81891, Precision: 0.75668, Recall: 0.93706, TPR: 0.93706, FPR: 0.29791\n",
      "Testing -- Iteration: 59, Loss: 0.01411, Accuracy: 0.88250, Precision: 0.89277, Recall: 0.87531, TPR: 0.87531, FPR: 0.10997\n",
      "Training -- Iteration: 60, Loss: 0.35035, Accuracy: 0.81984, Precision: 0.75744, Recall: 0.93801, TPR: 0.93801, FPR: 0.29698\n",
      "Testing -- Iteration: 60, Loss: 0.35035, Accuracy: 0.87828, Precision: 0.87534, Recall: 0.88845, TPR: 0.88845, FPR: 0.13235\n",
      "Training -- Iteration: 61, Loss: 0.19014, Accuracy: 0.81977, Precision: 0.75770, Recall: 0.93714, TPR: 0.93714, FPR: 0.29628\n",
      "Testing -- Iteration: 61, Loss: 0.19014, Accuracy: 0.87844, Precision: 0.87380, Recall: 0.89089, TPR: 0.89089, FPR: 0.13459\n",
      "Training -- Iteration: 62, Loss: 0.18237, Accuracy: 0.81703, Precision: 0.75291, Recall: 0.94068, TPR: 0.94068, FPR: 0.30521\n",
      "Testing -- Iteration: 62, Loss: 0.18237, Accuracy: 0.87516, Precision: 0.85830, Recall: 0.90526, TPR: 0.90526, FPR: 0.15633\n",
      "Training -- Iteration: 63, Loss: 0.34974, Accuracy: 0.82078, Precision: 0.75830, Recall: 0.93871, TPR: 0.93871, FPR: 0.29581\n",
      "Testing -- Iteration: 63, Loss: 0.34974, Accuracy: 0.87719, Precision: 0.86452, Recall: 0.90098, TPR: 0.90098, FPR: 0.14770\n",
      "Training -- Iteration: 64, Loss: 0.18489, Accuracy: 0.82219, Precision: 0.75849, Recall: 0.94241, TPR: 0.94241, FPR: 0.29667\n",
      "Testing -- Iteration: 64, Loss: 0.18489, Accuracy: 0.88406, Precision: 0.89335, Recall: 0.87806, TPR: 0.87806, FPR: 0.10965\n",
      "Training -- Iteration: 65, Loss: 0.52003, Accuracy: 0.82352, Precision: 0.76082, Recall: 0.94076, TPR: 0.94076, FPR: 0.29239\n",
      "Testing -- Iteration: 65, Loss: 0.52003, Accuracy: 0.88313, Precision: 0.88382, Recall: 0.88814, TPR: 0.88814, FPR: 0.12212\n",
      "Training -- Iteration: 66, Loss: 0.18668, Accuracy: 0.82230, Precision: 0.75890, Recall: 0.94178, TPR: 0.94178, FPR: 0.29581\n",
      "Testing -- Iteration: 66, Loss: 0.18668, Accuracy: 0.88391, Precision: 0.88682, Recall: 0.88600, TPR: 0.88600, FPR: 0.11829\n",
      "Training -- Iteration: 67, Loss: 0.18699, Accuracy: 0.82258, Precision: 0.75966, Recall: 0.94076, TPR: 0.94076, FPR: 0.29426\n",
      "Testing -- Iteration: 67, Loss: 0.18699, Accuracy: 0.88250, Precision: 0.87679, Recall: 0.89609, TPR: 0.89609, FPR: 0.13171\n",
      "Training -- Iteration: 68, Loss: 0.18546, Accuracy: 0.82320, Precision: 0.75912, Recall: 0.94390, TPR: 0.94390, FPR: 0.29612\n",
      "Testing -- Iteration: 68, Loss: 0.18546, Accuracy: 0.88453, Precision: 0.88838, Recall: 0.88539, TPR: 0.88539, FPR: 0.11637\n",
      "Training -- Iteration: 69, Loss: 0.01390, Accuracy: 0.82437, Precision: 0.76099, Recall: 0.94288, TPR: 0.94288, FPR: 0.29278\n",
      "Testing -- Iteration: 69, Loss: 0.01390, Accuracy: 0.88359, Precision: 0.87773, Recall: 0.89731, TPR: 0.89731, FPR: 0.13075\n",
      "Training -- Iteration: 70, Loss: 0.35609, Accuracy: 0.82105, Precision: 0.75610, Recall: 0.94484, TPR: 0.94484, FPR: 0.30133\n",
      "Testing -- Iteration: 70, Loss: 0.35609, Accuracy: 0.88219, Precision: 0.87426, Recall: 0.89884, TPR: 0.89884, FPR: 0.13523\n",
      "Training -- Iteration: 71, Loss: 0.17966, Accuracy: 0.82285, Precision: 0.75793, Recall: 0.94571, TPR: 0.94571, FPR: 0.29861\n",
      "Testing -- Iteration: 71, Loss: 0.17966, Accuracy: 0.88422, Precision: 0.87878, Recall: 0.89731, TPR: 0.89731, FPR: 0.12948\n",
      "Training -- Iteration: 72, Loss: 0.18382, Accuracy: 0.82699, Precision: 0.76386, Recall: 0.94374, TPR: 0.94374, FPR: 0.28843\n",
      "Testing -- Iteration: 72, Loss: 0.18382, Accuracy: 0.88078, Precision: 0.86373, Recall: 0.91045, TPR: 0.91045, FPR: 0.15026\n",
      "Training -- Iteration: 73, Loss: 0.18952, Accuracy: 0.82230, Precision: 0.75701, Recall: 0.94633, TPR: 0.94633, FPR: 0.30032\n",
      "Testing -- Iteration: 73, Loss: 0.18952, Accuracy: 0.87891, Precision: 0.85887, Recall: 0.91320, TPR: 0.91320, FPR: 0.15697\n",
      "Training -- Iteration: 74, Loss: 0.18372, Accuracy: 0.82418, Precision: 0.75910, Recall: 0.94681, TPR: 0.94681, FPR: 0.29706\n",
      "Testing -- Iteration: 74, Loss: 0.18372, Accuracy: 0.88344, Precision: 0.87433, Recall: 0.90159, TPR: 0.90159, FPR: 0.13555\n",
      "Training -- Iteration: 75, Loss: 0.52002, Accuracy: 0.82926, Precision: 0.76557, Recall: 0.94633, TPR: 0.94633, FPR: 0.28649\n",
      "Testing -- Iteration: 75, Loss: 0.52002, Accuracy: 0.88484, Precision: 0.87533, Recall: 0.90342, TPR: 0.90342, FPR: 0.13459\n",
      "Training -- Iteration: 76, Loss: 0.35203, Accuracy: 0.82559, Precision: 0.76215, Recall: 0.94366, TPR: 0.94366, FPR: 0.29115\n",
      "Testing -- Iteration: 76, Loss: 0.35203, Accuracy: 0.88984, Precision: 0.90097, Recall: 0.88142, TPR: 0.88142, FPR: 0.10134\n",
      "Training -- Iteration: 77, Loss: 0.18321, Accuracy: 0.82758, Precision: 0.76292, Recall: 0.94767, TPR: 0.94767, FPR: 0.29115\n",
      "Testing -- Iteration: 77, Loss: 0.18321, Accuracy: 0.88844, Precision: 0.88875, Recall: 0.89364, TPR: 0.89364, FPR: 0.11701\n",
      "Training -- Iteration: 78, Loss: 0.35193, Accuracy: 0.82688, Precision: 0.76252, Recall: 0.94657, TPR: 0.94657, FPR: 0.29146\n",
      "Testing -- Iteration: 78, Loss: 0.35193, Accuracy: 0.88906, Precision: 0.88795, Recall: 0.89609, TPR: 0.89609, FPR: 0.11829\n",
      "Training -- Iteration: 79, Loss: 0.01157, Accuracy: 0.82250, Precision: 0.75670, Recall: 0.94767, TPR: 0.94767, FPR: 0.30125\n",
      "Testing -- Iteration: 79, Loss: 0.01157, Accuracy: 0.88719, Precision: 0.87901, Recall: 0.90373, TPR: 0.90373, FPR: 0.13012\n",
      "Training -- Iteration: 80, Loss: 0.18111, Accuracy: 0.82914, Precision: 0.76418, Recall: 0.94924, TPR: 0.94924, FPR: 0.28960\n",
      "Testing -- Iteration: 80, Loss: 0.18111, Accuracy: 0.89203, Precision: 0.90671, Recall: 0.87928, TPR: 0.87928, FPR: 0.09463\n",
      "Training -- Iteration: 81, Loss: 0.18078, Accuracy: 0.82727, Precision: 0.76200, Recall: 0.94893, TPR: 0.94893, FPR: 0.29302\n",
      "Testing -- Iteration: 81, Loss: 0.18078, Accuracy: 0.89016, Precision: 0.89197, Recall: 0.89334, TPR: 0.89334, FPR: 0.11317\n",
      "Training -- Iteration: 82, Loss: 0.00950, Accuracy: 0.83062, Precision: 0.76586, Recall: 0.94963, TPR: 0.94963, FPR: 0.28703\n",
      "Testing -- Iteration: 82, Loss: 0.00950, Accuracy: 0.89312, Precision: 0.91823, Recall: 0.86828, TPR: 0.86828, FPR: 0.08088\n",
      "Training -- Iteration: 83, Loss: 0.18290, Accuracy: 0.82895, Precision: 0.76411, Recall: 0.94885, TPR: 0.94885, FPR: 0.28960\n",
      "Testing -- Iteration: 83, Loss: 0.18290, Accuracy: 0.89031, Precision: 0.88108, Recall: 0.90801, TPR: 0.90801, FPR: 0.12820\n",
      "Training -- Iteration: 84, Loss: 0.18499, Accuracy: 0.83242, Precision: 0.76776, Recall: 0.95042, TPR: 0.95042, FPR: 0.28424\n",
      "Testing -- Iteration: 84, Loss: 0.18499, Accuracy: 0.88047, Precision: 0.85500, Recall: 0.92268, TPR: 0.92268, FPR: 0.16368\n",
      "Training -- Iteration: 85, Loss: 0.35375, Accuracy: 0.83039, Precision: 0.76466, Recall: 0.95176, TPR: 0.95176, FPR: 0.28960\n",
      "Testing -- Iteration: 85, Loss: 0.35375, Accuracy: 0.89312, Precision: 0.89165, Recall: 0.90037, TPR: 0.90037, FPR: 0.11445\n",
      "Training -- Iteration: 86, Loss: 0.17764, Accuracy: 0.82766, Precision: 0.76166, Recall: 0.95089, TPR: 0.95089, FPR: 0.29418\n",
      "Testing -- Iteration: 86, Loss: 0.17764, Accuracy: 0.89344, Precision: 0.89171, Recall: 0.90098, TPR: 0.90098, FPR: 0.11445\n",
      "Training -- Iteration: 87, Loss: 0.18082, Accuracy: 0.83199, Precision: 0.76624, Recall: 0.95270, TPR: 0.95270, FPR: 0.28735\n",
      "Testing -- Iteration: 87, Loss: 0.18082, Accuracy: 0.89031, Precision: 0.88153, Recall: 0.90740, TPR: 0.90740, FPR: 0.12756\n",
      "Training -- Iteration: 88, Loss: 0.18392, Accuracy: 0.82941, Precision: 0.76342, Recall: 0.95183, TPR: 0.95183, FPR: 0.29162\n",
      "Testing -- Iteration: 88, Loss: 0.18392, Accuracy: 0.88844, Precision: 0.87485, Recall: 0.91229, TPR: 0.91229, FPR: 0.13651\n",
      "Training -- Iteration: 89, Loss: 0.00855, Accuracy: 0.83402, Precision: 0.76860, Recall: 0.95309, TPR: 0.95309, FPR: 0.28369\n",
      "Testing -- Iteration: 89, Loss: 0.00855, Accuracy: 0.89516, Precision: 0.89880, Recall: 0.89578, TPR: 0.89578, FPR: 0.10550\n",
      "Training -- Iteration: 90, Loss: 0.18188, Accuracy: 0.83234, Precision: 0.76654, Recall: 0.95301, TPR: 0.95301, FPR: 0.28696\n",
      "Testing -- Iteration: 90, Loss: 0.18188, Accuracy: 0.89625, Precision: 0.90173, Recall: 0.89456, TPR: 0.89456, FPR: 0.10198\n",
      "Training -- Iteration: 91, Loss: 0.34932, Accuracy: 0.83387, Precision: 0.76844, Recall: 0.95301, TPR: 0.95301, FPR: 0.28393\n",
      "Testing -- Iteration: 91, Loss: 0.34932, Accuracy: 0.88703, Precision: 0.86697, Recall: 0.92023, TPR: 0.92023, FPR: 0.14770\n",
      "Training -- Iteration: 92, Loss: 0.00894, Accuracy: 0.83254, Precision: 0.76668, Recall: 0.95325, TPR: 0.95325, FPR: 0.28680\n",
      "Testing -- Iteration: 92, Loss: 0.00894, Accuracy: 0.89719, Precision: 0.89945, Recall: 0.89945, TPR: 0.89945, FPR: 0.10518\n",
      "Training -- Iteration: 93, Loss: 0.18158, Accuracy: 0.83395, Precision: 0.76819, Recall: 0.95380, TPR: 0.95380, FPR: 0.28455\n",
      "Testing -- Iteration: 93, Loss: 0.18158, Accuracy: 0.89141, Precision: 0.88020, Recall: 0.91167, TPR: 0.91167, FPR: 0.12980\n",
      "Training -- Iteration: 94, Loss: 0.01032, Accuracy: 0.83539, Precision: 0.76976, Recall: 0.95435, TPR: 0.95435, FPR: 0.28222\n",
      "Testing -- Iteration: 94, Loss: 0.01032, Accuracy: 0.89062, Precision: 0.87493, Recall: 0.91718, TPR: 0.91718, FPR: 0.13715\n",
      "Training -- Iteration: 95, Loss: 0.00772, Accuracy: 0.83367, Precision: 0.76741, Recall: 0.95482, TPR: 0.95482, FPR: 0.28610\n",
      "Testing -- Iteration: 95, Loss: 0.00772, Accuracy: 0.89672, Precision: 0.90331, Recall: 0.89364, TPR: 0.89364, FPR: 0.10006\n",
      "Training -- Iteration: 96, Loss: 0.17652, Accuracy: 0.83500, Precision: 0.76835, Recall: 0.95647, TPR: 0.95647, FPR: 0.28509\n",
      "Testing -- Iteration: 96, Loss: 0.17652, Accuracy: 0.89844, Precision: 0.90363, Recall: 0.89700, TPR: 0.89700, FPR: 0.10006\n",
      "Training -- Iteration: 97, Loss: 0.18092, Accuracy: 0.83574, Precision: 0.76962, Recall: 0.95568, TPR: 0.95568, FPR: 0.28284\n",
      "Testing -- Iteration: 97, Loss: 0.18092, Accuracy: 0.89563, Precision: 0.88750, Recall: 0.91137, TPR: 0.91137, FPR: 0.12084\n",
      "Training -- Iteration: 98, Loss: 0.34940, Accuracy: 0.83645, Precision: 0.77042, Recall: 0.95584, TPR: 0.95584, FPR: 0.28160\n",
      "Testing -- Iteration: 98, Loss: 0.34940, Accuracy: 0.89578, Precision: 0.88638, Recall: 0.91320, TPR: 0.91320, FPR: 0.12244\n",
      "Training -- Iteration: 99, Loss: 0.34990, Accuracy: 0.83805, Precision: 0.77126, Recall: 0.95851, TPR: 0.95851, FPR: 0.28105\n",
      "Testing -- Iteration: 99, Loss: 0.34990, Accuracy: 0.89578, Precision: 0.91362, Recall: 0.87928, TPR: 0.87928, FPR: 0.08696\n",
      "Training -- Iteration: 100, Loss: 0.18235, Accuracy: 0.83754, Precision: 0.77076, Recall: 0.95820, TPR: 0.95820, FPR: 0.28175\n",
      "Testing -- Iteration: 100, Loss: 0.18235, Accuracy: 0.89438, Precision: 0.88065, Recall: 0.91779, TPR: 0.91779, FPR: 0.13012\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'trainAccuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12116/2105984418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tab:blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_eval_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trainAccuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tab:green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Loss and Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfancybox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframealpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'trainAccuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAINING_MODE:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device == 'cuda':\n",
    "        print(\"--------------Found CUDA device. Training on GPU.--------------\")\n",
    "    else:\n",
    "        print(\"--------------Training on CPU--------------\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Creating testing and training datasets\n",
    "    train_set = torch.utils.data.TensorDataset(torch.Tensor(dataset.x_train).long().cuda(), torch.Tensor(dataset.y_train).long().cuda())\n",
    "    test_set = torch.utils.data.TensorDataset(torch.Tensor(dataset.x_test).long().cuda(), torch.Tensor(dataset.y_test).long().cuda())\n",
    "\n",
    "    # Train model\n",
    "    learning_rate = 0.01\n",
    "    batch_size = 12\n",
    "    numOfIter = 100\n",
    "    trainLoss, testLoss = train(model, dataset, learning_rate, batch_size, train_set, test_set, numOfIter)\n",
    "\n",
    "    # Delete old save data\n",
    "    if save_path.exists():\n",
    "        save_path.unlink()\n",
    "    if cpu_flag_path.exists():\n",
    "        cpu_flag_path.unlink()\n",
    "    if gpu_flag_path.exists():\n",
    "        gpu_flag_path.unlink()\n",
    "\n",
    "    # Write save and training device marker\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    if device == 'cuda':\n",
    "        Path(gpu_flag_path).touch()\n",
    "    else:\n",
    "        Path(cpu_flag_path).touch()\n",
    "\n",
    "    #plot losses/accuracies\n",
    "    x = list(range(1, numOfIter + 1))\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    plt.plot(x, trainLoss, label='Training Loss', color='tab:blue', linewidth=3)\n",
    "    plt.plot(x, model.train_eval_info['trn_accuracy'], label='Training Accuracy', color='tab:green', linewidth=3)\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.legend(fancybox=True, framealpha=0.5, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    plt.plot(x, testLoss, label='Testing Loss', color='tab:blue', linewidth=3)\n",
    "    plt.plot(x, model.test_eval_info['trn_accuracy'], label='Testing Accuracy', color='tab:green', linewidth=3)\n",
    "    plt.title('Testing Loss and Accuracy')\n",
    "    plt.legend(fancybox=True, framealpha=0.5, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    # trainEval = [accuracy, precision, recall, true-positive-rate, false-positive-rate, true_pos, false_pos, true_neg, false_neg]\n",
    "    confusion_matrix(model.train_eval_info['tp'], model.train_eval_info['fp'], model.train_eval_info['tn'], model.train_eval_info['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadlineClassifier(\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (embedding): Embedding(23328, 64, padding_idx=0)\n",
       "  (fc): Linear(in_features=2320, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_device = 'cuda' if Path(gpu_flag_path).exists() else 'cpu'\n",
    "my_device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = HeadlineClassifier(seq_len, vocab_size, embedding_size, dropout, out_size, stride, filters)\n",
    "if save_device == 'cuda' and my_device == 'cpu':\n",
    "    model.load_state_dict(torch.load(save_path, map_location=my_device))\n",
    "elif save_device == 'cuda' and my_device == 'cuda':\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.to(my_device)\n",
    "elif save_device == 'cuda' and my_device == 'cuda':\n",
    "    model.load_state_dict(torch.load(save_path, map_location=\"cuda:0\"))\n",
    "    model.to(device)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    \n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper__thnn_conv2d_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12116/3579736283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"How I became a millionare\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CLICKBAIT FOUND ( result =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\")\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12116/3579736283.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_phrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tokenized_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Disable gradient calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_phrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12116/4135578759.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_X)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mlayerPasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[1;31m#TODO: Why not sigmoid (there are a few common functions we can try)? Maybe this can be a question we answer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    295\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 297\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    298\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper__thnn_conv2d_forward)"
     ]
    }
   ],
   "source": [
    "#Run a prediction test\n",
    "def predict(string) -> float:\n",
    "    test_phrase = dataset.get_tokenized_string(string)\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        pred = model(torch.tensor(test_phrase))\n",
    "        return pred.detach().numpy()\n",
    "\n",
    "prediction = predict(\"How I became a millionare\")\n",
    "if prediction > 0.5:\n",
    "    print(\"CLICKBAIT FOUND ( result =\", prediction, \")\")\n",
    "else:\n",
    "    print(\"Not clickbait ( result =\", prediction, \")\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "991fbe55e20aa96684a77864442132e855c0c354e4a8fc77b9a964190396388d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
